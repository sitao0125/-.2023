# -.2023
滇池学院大四 第一次作业  用于实现对于外卖情感分析
#有两个很大的词向量文件，上传不上来，贴一个百度网盘链解，直接复制即可，链解永久有效
链接：https://pan.baidu.com/s/1CtMpjHC5H5V77557JEvjHA?pwd=hu3e 
提取码：hu3e 
--来自百度网盘超级会员V3的分享

# 情感分析模型 - README

本项目是一个用于构建情感分析模型的示例代码。该模型可以用于分析文本评论的情感，判断评论是正面的还是负面的。项目中使用了自然语言处理（NLP）技术和深度学习方法来实现情感分析。

## 项目结构

项目包含以下主要文件和文件夹：

- `main.py`：包含了整个情感分析模型的代码。模型的构建、训练和评估都在这个文件中完成。

- `waimai_10k.csv`：包含了用于训练和测试情感分析模型的数据集。数据集中包含了用户的评论和情感标签。

- `stopwords.txt`：包含了用于文本预处理的停用词表。停用词表中的词语将被从评论中去除。

- `sgns.merge.word.kv`：预训练的中文词向量模型，用于词向量的加载和构建嵌入层。

## 使用说明

1. 安装依赖项：在运行代码之前，确保已安装所需的依赖项。可以使用以下命令安装 Python 依赖项：

   ```bash
   pip install pandas numpy tensorflow jieba gensim matplotlib seaborn scikit-learn

主要通NLP相关实现外卖情感分析
编写代码完成外卖评价的情感分析。把提供的数据集划分为训练集、测试集，设计并训练模型、
对测试集进行预测,并把预测值和测试集的标签进行计算f1分值

数据准备：
   - `clearTxt`函数用于处理文本数据，将一些特定的字符替换成逗号。
   - `Txt2Seq`函数用于对文本进行分词，并去除停用词。
   - 从CSV文件中读取数据，并对每条评论文本进行处理，存储在`texts`中，标签存储在`labels`中。
数据分割：
   - 使用`train_test_split`函数将数据分割成训练集和测试集。
文本处理：
   - 使用`Tokenizer`对文本进行编码，并限制词汇表的大小为`max_words`，同时设置了一个特殊的词汇"OOO"用于表示未登录词。
   - 将训练集和测试集的文本数据转换为序列（数字特征），并对序列进行填充，以保证它们的长度相同。
 加载预训练的词向量模型：
   - 使用`gensim`库加载了预训练的词向量模型`sgns.merge.word.kv`，这个模型包含了每个词汇的词向量表示。
构建情感分析模型：
   - 创建一个Sequential模型，依次添加了嵌入层（Embedding Layer）、平坦层（Flatten Layer）、一个具有ReLU激活函数的密集层（Dense Layer），以及一个具有sigmoid激活函数的输出层。这个模型用于进行情感分析，输出一个二元分类结果（正面或负面情感）。
 编译模型：
   - 使用`model.compile`方法编译模型，选择了Adam优化器和二元交叉熵损失函数，并指定了训练过程中的性能指标为准确率。
模型训练：
   - 使用`model.fit`方法对模型进行训练，指定了训练集、迭代次数（epochs）、验证集等参数。
模型评估：
   - 使用`model.evaluate`方法对模型在测试集上进行评估，计算了测试集的损失和准确率。
 预测外卖评价情感：
    - 对测试集的情感进行预测，并计算了F1分数等性能指标。
可视化：
    - 使用`matplotlib`和`seaborn`库绘制了训练过程中的损失、准确率以及混淆矩阵等图表，以便对模型性能进行可视化分析。

总体来说，这段代码实现了一个基于深度学习的文本情感分析模型，用于预测外卖评论的情感倾向（正面或负面）。通过加载预训练的词向量模型，可以提高模型对文本特征的理解能力。最后，通过可视化工具，对模型的训练过程和性能进行了分析和展示。

对于可视化代码：
绘制了训练集和验证集的损失值随着训练周期的变化。它使用history对象中的history字典，其中包含了训练过程中的损失和准确度历史记录。这些历史记录是在模型训练期间自动记录的。


plt.plot(history.history['loss'], label='Training Loss')
plt.plot(history.history['val_loss'], label='Validation Loss')
plt.xlabel('Epochs')
plt.ylabel('Loss')
plt.legend()
plt.show()
创建了一个折线图，横轴表示训练周期（epochs），纵轴表示损失值。它展示了训练集和验证集的损失值随着训练周期的增加而变化的趋势。根据损失值的趋势来判断模型的训练情况。



可视化训练和验证准确度：接下来的代码块绘制了训练集和验证集的准确度随着训练周期的变化。同样，它使用history对象中的history字典中的数据。

plt.plot(history.history['accuracy'], label='Training Accuracy')
plt.plot(history.history['val_accuracy'], label='Validation Accuracy')
plt.xlabel('Epochs')
plt.ylabel('Accuracy')
plt.legend()
plt.show()
这段代码创建了一个折线图，横轴表示训练周期（epochs），纵轴表示准确度。它展示了训练集和验证集的准确度随着训练周期的增加而变化的趋势。准确度是指模型在给定数据集上的分类性能。

混淆矩阵可视化：最后，这段代码使用Seaborn库创建了一个热力图，用于可视化混淆矩阵。混淆矩阵显示了模型在测试数据上的分类性能。

python
Copy code
plt.figure(figsize=(8, 6))
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=['Negative', 'Positive'], yticklabels=['Negative', 'Positive'])
plt.xlabel('Predicted')
plt.ylabel('Actual')
plt.title('Confusion Matrix')
plt.show()
这段代码使用Seaborn的heatmap函数创建热力图，其中cm是混淆矩阵，用于表示模型的真正例、真负例、假正例和假负例的数量。热力图以颜色的形式表示这些值，帮助你更直观地了解模型的分类性能。

通过这些可视化，你可以更好地理解和评估你的情感分析模型的性能，包括损失、准确度和分类结果。



验证损失（Validation Loss）是在机器学习和深度学习中用于评估模型性能的一个重要指标。它通常用于监控模型在验证数据集上的性能。

验证损失表示模型在验证数据集上的预测值与实际标签之间的差异或误差。具体来说，它是模型针对验证数据集计算的损失函数值。损失函数通常是一种衡量模型预测与真实标签之间差异的度量，它越小越好。通常，均方误差（Mean Squared Error）和交叉熵（Cross Entropy）是常用的损失函数之一。

验证损失的主要作用包括：

评估模型性能：验证损失用于衡量模型在未见过的验证数据上的性能。较低的验证损失表示模型在验证数据上的预测更接近真实标签，因此模型的性能更好。
监控过拟合：通过观察训练损失和验证损失之间的差异，可以判断模型是否存在过拟合问题。如果训练损失持续下降而验证损失开始上升，可能意味着模型在训练数据上过拟合，失去了对未见过数据的泛化能力。
超参数调优：验证损失可用于选择不同超参数配置（例如学习率、模型结构等）的最佳组合。通常，通过尝试不同的超参数组合，选择验证损失最小的组合来改进模型。
提前停止：验证损失还可用于实现提前停止（Early Stopping）策略。如果在一定数量的训练周期内验证损失没有显著改善，可以停止训练，以避免过拟合。






